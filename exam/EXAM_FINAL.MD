<img src="../extra/img/innopolis-logo.svg" height="48px" href="#"/>

# ИТОГОВЫЙ ПРОЕКТ
# Игровая перспектива 2025: Исследование ключевых факторов разработки новой компьютерной игры

Проект выполнен в рамках итоговой аттестации по курсу: **"Программная инженерия. Разработка программного обеспечения (SQL для начинающих специалистов)"** в **Университете Иннополис**.

Исполнитель: Боталов Константин Владимирович

Москва, 2024 г.

* [Ссылка](https://github.com/botalov-pro/innopolis-practicum/blob/main/exam/EXAM_FINAL.MD) на настоящую работу.
* [Ссылка](https://github.com/botalov-pro/innopolis-practicum/blob/main/exam/pdf/EXAM_FINAL_PRESENTATION.pdf) на презентацию проекта.
* [Ссылка](https://github.com/botalov-pro/innopolis-practicum/blob/main/exam/sql/exam_final.sql) на итоговый SQL-файл.
* [Ссылка](https://github.com/botalov-pro/innopolis-practicum/blob/main/exam/py/Botalov_KV_Global_games_sales_Analysis.ipynb) на итоговый файл Jupiter Notebook.

## Содержание

1. [Цель и задачи проекта](#цель-и-задачи-проекта)
2. [Основные инструменты проекта](#основные-инструменты-проекта)
3. [Описание исходных данных](#описание-исходных-данных)
4. [Загрузка данных](#загрузка-данных)
5. [Первичное исследование данных](#первичное-исследование-данных)
6. [Перенос данных в базу данных](#перенос-данных-в-базу-данных)
7. [Анализ и подготовка данных средствами PostgreSQL](#анализ-и-подготовка-данных-средствами-postgresql)
8. [Проектирование и создание целевой базы данных](#проектирование-и-создание-целевой-базы-данных)
9. [Анализ ключевых факторов, влияющих на успех разработки компьютерной игры](#анализ-ключевых-факторов-влияющих-на-успех-разработки-компьютерной-игры)
10. [Основные выводы и рекомендации](#основные-выводы-и-рекомендации)
11. [Приложение 1.](#)
11. [Приложение 2. Разворачивание Docker-контейнера с базой данных PostgreSQL для выполнения проекта](#приложение-2-разворачивание-docker-контейнера-с-базой-данных-postgresql-для-выполнения-проекта)

## Цель и задачи проекта

**Цель проекта** — определить c использованием SQL и методов программирования наиболее перспективные жанры и платформы для разработки компьютерных игр в 2025 году, а также рекомендовать подходящих издателей и выявить успешные игровые серии на основе анализа исторических данных о продажах.

**Задачи проекта:**

1. Первичная обработка данных
2. Первичное исследование данных
3. Импорт данных в базу данных
4. Подготовка и первичный анализ данных средствами PostgreSQL
5. Проектирование и создание базы данных
6. Анализ ключевых факторов, влияющих на успех разработки компьютерной игры
7. Интерпретация полученных результатов

## Основные инструменты проекта

- **Рабочая операционная система:** Windows 11 Home 23H2
- **Среда контейнеризации приложений:** Docker Desktop 4.35.1
- **Система управления базами данных:** PostgreSQL 17.0 / pgAdmin 4 v8.12 (на базе ОС Debian) 
- **Языки программирования:** Python 3.10, SQL, PL/pgSQL
- **Система управления версиями:** GIT 2.45.1 
- **Интерактивное веб-приложение:** Jupyter Server 2.14.2 / Jupiter Notebook 7.2.2
- **Библиотеки:** Pandas 2.2.3, SQLAlchemy 2.0.36, psycopg 2.9.10

[Полный список зависимостей проекта](https://github.com/botalov-pro/innopolis-practicum/blob/main/requirements.txt)

## Описание исходных данных

Данные содержат информацию о продажах более 64 000 видеоигр во всем мире по состоянию на 2024 год с указанием наименований видеоигр, их издателях, количестве продаж, оценок критиков.

Информация автоматически собрана при помощи программного робота [vgchartz-crawler](https://github.com/baynebrannen/vgchartz-crawler) с сайта [Video Game Charts](https://www.vgchartz.com/). Владелец сайта - компания "VGChartz" (Video Game Charts) основана Бреттом Уолтоном и занимается аналитикой и исследованиями в мировой игровой индустрии с 2005 года.  

Файл с данными представлен файлом в формате CSV (Comma-Separated Values), который является распространенным и удобным способом представления табличных данных, что облегчает их обработку, анализ и
интеграцию с различными системами управления базами данных, программными средствами и аналитическими инструментами. Следовательно, мы можем этот набор данных загрузить и обработать
програмными средствами.

Последняя дата обновления данных: 29 января 2024 г. 18:58.

Данные распространяются под лицензией [ODC Attribution License (ODC-By)](https://opendatacommons.org/licenses/by/1-0/index.html)

Ссылка на исходный набор данных: https://www.kaggle.com/datasets/asaniczka/video-game-sales-2024

## Загрузка данных

1. Для первоначальной загрузки и анализа данных будем использовать средства Jupiter Notebook, Python, Pandas, так как мы не знаем какого рода данные содержатся в файле, их структуру, качество, количество и размер.  
2. Вручную загружаем исходный файл с расширением CSV в каталог ./src
3. В Jupiter Notebook импортируем необходимые для работы библиотеки:

```python
# Импорт необходимых библиотек
import os.path                      # os - для работы с файлами операционной системы
import pandas as pd                 # pandas - для работы с табличными данными
```

![](img/img_38.png)

4. Указываем путь к нашему файлу данных и проверяем, что файл доступен для загрузки:

```python
# Путь к исходному CSV-файлу
file_path = '../src/vgchartz-2024.csv'

# Проверка существования файла по заданному пути
os.path.exists(file_path)
```

![](img/img_39.png)

**Результат:** файл с данными существует в рабочем каталоге и доступен для загрузки. 

5. Загружаем данные файла в DataFrame Pandas:

```python
# Загрузка CSV файла в DataFrame Pandas
try:
    df = pd.read_csv(file_path)
    display('Файл загружен!')
except FileNotFoundError:
    display('Файл отсутствует!')
```

![](img/img_40.png)

6. Файл с данными загружен в дата-фрейм Pandas и готов для первичного исследования

## Первичное исследование данных

Первичное исследование данных в файле позволит ознакомиться с данными в нем, понять его структуру и подготовить данные для дальнейшей загрузки в базу данных.

Для первичного исследования данных продолжим использовать Python-библиотеку **Pandas** для анализа загруженного дата-фрейма. 

### Проверка типа загруженных данных

Проверим, что дата-фрейм - это наш тип загруженных данных 

```python
# Вывод типа переменной df - исследуемого набора данных
type(df)
```

![](img/img_41.png)

Данные загружены в виде необходимого нам дата-фрейма Pandas (*.DataFrame).
Приведение к другим типам данных в настоящее время не требуется.

### Проверка наличия данных

Для проверки наличия данных в файле вычислим 10 произвольных строк из набора данных:

```python
# Выводим десять случайных строк набора данных
df.sample(10)
```

![](img/img_42.png)

**Результат:** данные в наборе существуют и мы можем с ними работать.

### Определение размера и формы набора данных

Вычислим размер нашего набора данных и выведем названия столбцов:

```python
# Получение размера набора данных (количество строк и столбцов)
print(df.shape)

# Получение списка названий столбцов
print(df.columns)
```

![](img/img_43.png)

**Результат:** Наши данные содержат 64016 записей в 14 столбцах:

1. **img** - относительная ссылка (URI) на обложку игры с сайта [Video Game Charts](https://www.vgchartz.com/);
2. **title** - название игры;
3. **console** - компьютерная платформа (консоль) для которой была выпущена игра;
4. **genre** - жанр игры;
5. **publisher** - наименование издателя игры;
6. **developer** - наименование разработчика игры;
7. **critic_score** - оценка критиков (из 10);
8. **total_sales** - количество продаж во всем мире (в миллионах экземпляров);
9. **na_sales** - количество продаж в Северной Америке (в миллионах экземпляров);
10. **jp_sales** - количество продаж в Японии (в миллионах экземпляров);
11. **pal_sales** - количество продаж в странах PAL: Европа, Африка (в миллионах экземпляров);
12. **other_sales** - количество продаж в других регионах (в миллионах экземпляров);
13. **release_date** - дата выхода (релиза) игры;
14. **last_update** - дата последнего обновления данных.

### Проверка формата данных набора

Отобразим весь наш набор данных в сокращенном виде:

```python
# Отображение набора данных в сокращенном виде
display(df)
```

![](img/img_44.png)

![](img/img_45.png)

**Результат:** на первый взгляд какие-либо возможные проблемы с форматированием данных отсутствуют. Видим, что отсутствуют данные (NaN) в столбцах **critic_score**, **total_sales**, **na_sales**, **jp_sales**, **pal_sales**, **other_sales**, **release_date**, **last_update**.

### Определение количества уникальных значений при помощи Pandas

Для каждого столбца определим количество уникальных значений:

```python
# Подсчет количества уникальных значений для каждого столбца данных
display(df.nunique())
```

![](img/img_56.png)

**Результат:** из приведенных данных видим, что у нас 39798 уникальных названий игр, 81 платформа для компьютерных игр, 20 жанров, 3383 издателя и 8862 разработчика. Эта информация нам в дальнейшем поможет проверить правильность импорта данных и определить варианты оптимизации базы данных.

### Формат данных значений в наборе

Узнаем формат и количество значений в нашем наборе данных:

```python
# Вывод сводной информации о наборе данных
df.info()
```

![](img/img_46.png)

**Результат:** Данные занимают в памяти 6,8 Мб.

Значения в наборе представлены 8 категориальными и 6 числовыми признаками с
типами:
- **текстовые или смешанные данные** (object): img, title, console, genre, publisher, developer, release_date, last_update.  
- **число с плавающей запятой** (float64): critic_score, total_sales, na_sales, jp_sales, pal_sales, other_sales.

Видим, что в наборе данных присутствуют null-значения. Определим количество таких значений в столбцах:

```python
# Подсчет количества null-значений в наборе данных
df.isnull().sum()
```

![](img/img_47.png)

**Результат:** Как видим, в 9 столбцах из 14 (developer, critic_score, total_sales, na_sales, jp_sales, pal_sales, other_sales, release_date, release_date, last_update) присутствуют null-значения. Требуется обработка отсутствующих значений, так как в дальнейшем они могут вызвать ошибки при вычислениях.

Определим минимумы и максимумы для числовых значений. Это поможет нам в дальнейшем оптимальным образом построить структуру базы данных.

```python
# Определение минимумов и максимумов для числовых значений
df.describe()
```

![](img/img_48.png)

**Результат:** значения только в столбце critic_score ограничены значениями оценок от 1 до 10. Нижняя граница остальных числовых столбцов находится на отметке 0 (нет продаж или нет данным по ним). Максимальное значение фиксированной границы не имеет, так как данные актуализируются и растет количество проданных экземпляров игр. 

Данные загружены в дата-фрейм Pandas, проанализированы и готовы к импорту в систему управления базами данных.

## Перенос данных в базу данных

Для создания базы данных будем использовать систему управления реляционными базами данных PostgreSQL, развернутую в Docker-контейнере на базе операционной системы Debian. Для администрирования СУБД будем использовать pgAdmin.

### Создание чистой базы данных SALES

C использованием pgAdmin Query Tool создаем чистую базы данных **SALES**, предварительно удалив имеющуюся базу данных (если таковая имелась):

```postgresql
/* Удаление созданной базы данных SALES (если ранее такая база данных существовала) */
DROP DATABASE IF EXISTS sales;
```

![](img/img_49.png)

```postgresql
/* Создание чистой базы данных SALES */
CREATE DATABASE sales;
```

![](img/img_50.png)

Убеждаемся, что наша база данных SALES создалась:

```postgresql
/* Проверяем, что создалась база данных SALES */
SELECT datname FROM pg_database
WHERE datname='sales';
```

![](img/img_51.png)

**Результат:** чистая база данных SALES в PostgreSQL успешно создана.

### Задание 2: Импорт данных в базу данных

Для импорта данных дата-фрейма в базу данных SALES системы управления PostgreSQL будем использовать средства Pandas и SQLAlchemy.

В Jupiter Notebook импортируем необходимые нам библиотеки:

```python
# Импорт необходимых библиотек для переноса данных
from sqlalchemy import create_engine    # Набор инструментов для работы с SQL из Python
import psycopg2     # Коннектор к СУБД PostgreSQL из Python
```

![](img/img_52.png)

Создаем подключение к базе данных SALES и переносим данные из нашего дата-фрейма в таблицу SALES_IMPORT:

```python
# Импорт дата-фрейма в PostgreSQL средствами Pandas и SQLAlchemy

# Строка подключения к базе данных SALES
# Пример: 'postgresql://username:password@localhost:5432/your_database'
db_connection = create_engine('postgresql://postgres:changeme@localhost:5432/sales')

# Перенос данных из дата-фрейма в таблицу базы данных
df.to_sql(
    name='sales_import',    # Имя целевой таблицы
    con=db_connection,      # Подключение к базе данных
    if_exists='replace',    # если таблица уже существует, перезаписываем новыми знчениями
    index=False             # без индекса, он нам пока не требуется
)
```

![](img/img_53.png)

**Результат:** код успешно отработал и завершил перенос данных с дата-фрейма в базу данных. 

Так как метод **DataFrame.to_sql()** библиотеки **Pandas** не отражать точное количество записанных строк в базу данных, то проверяем успешность переноса данных:

```postgresql
/* Проверка количества импортированных данных в таблицу SALES_IMPORT */
SELECT COUNT(*) AS IMPORT_COUNT
    FROM sales_import;
```

![](img/img_54.png)

**Результат:** количество перенесенных строк соответствует количеству записей в дата-фрейме (64016).

Проверим качественный перенос данных и заполнение таблицы SALES_IMPORT. Выведем 10 произвольных строк из таблицы SALES_IMPORT:

```postgresql
/*
    Проверка качественного переноса импортированных данных в таблицу SALES_IMPORT.
    Вывод 10 случайных строк таблицы
*/
SELECT *
    FROM sales_import
    ORDER BY
        RANDOM()  -- Запускаем механизм случайности...
    LIMIT 10;  -- ...и извлекаем 10 случайных строк.
```

![](img/img_55.png)

**Результат:** данные успешно перенесены и теперь мы можем приступить к их анализу и оптимизации средствами SQL. 

## Анализ и подготовка данных средствами PostgreSQL

После того как мы загрузили данные в нашу базу данных необходимо их проанализировать средствами SQL и подготовить для дальнейшей оптимизации базы данных.

### Задание 3: Определение количества уникальных значений при помощи SQL

Определим с помощью SQL-запросов количество уникальных значений в нашей импортированной таблице SALES_IMPORT по каждому столбцу и сравним эти значения со [значениями, полученными при помощи библиотеки Pandas](#определение-количества-уникальных-значений-при-помощи-pandas):

```postgresql
/* Вывод таблицы с количеством уникальных значений по каждому столбцу */
DO $$
DECLARE
  cols TEXT;  -- Переменная для хранения агрегированного списка

BEGIN

    /*
        Очищаем (удаляем) временную таблицу counter
        перед ее заполнением
     */
    DROP TABLE IF EXISTS temp_counter;

    cols := string_agg(  -- объединяем строки в одну строку с разделителем (запятая)
                    'COUNT(DISTINCT ' || column_name::TEXT || ') '  || column_name::TEXT, ','
            )
    FROM (
        /*  Подзапрос для получения всех имен колонок из таблицы SALES_IMPORT */
        SELECT column_name
            FROM information_schema.columns
            WHERE
                table_name = 'sales_import'
            ) AS c;

    /*
       Создаем временную таблицу,
       где в качестве столбцов будут строки
       из переменной COLS (названия столбцов)
     */
    EXECUTE format(
            'CREATE TEMP TABLE temp_counter AS SELECT %s FROM sales_import;',
            cols
            );

END $$;

SELECT * FROM temp_counter;  -- Вывод данных из временной таблицы
```

![](img/img_57.png)

**Результат:** при помощи SQL-запроса мы получили данные о 39798 уникальном названии игры, 81 уникальной платформе, 20 уникальных жанрах, 3383 уникальном издателе, 8862 уникальном разработчике. Эти значения полностью совпадают со [значениями, полученными при помощи библиотеки Pandas](#определение-количества-уникальных-значений-при-помощи-pandas), что лишний раз подтверждает корректность импортированных данных. Кроме того, можно убедиться, что специальными библиотеками (типа Pandas) быстрее и проще анализировать данные нежели с использованием SQL-запросов.  

### Задание 4: Очистка от null-значений

Определим количество null-значений в нашей таблице SALES_IMPORT в каждом столбце:

```postgresql
/*
    Подсчет количества NULL-значений по каждому столбцу
*/
DO $$
DECLARE
  cols TEXT;  -- Переменная для хранения агрегированного списка

BEGIN

    -- Удаляем временную таблицу, если она существует
    DROP TABLE IF EXISTS temp_counter;

    cols := string_agg(  -- Объединяем строки в одну строку с разделителем (запятая)

                    /* Получаем разницу между общим количеством записей и ненулевыми значениями */
                    'COUNT(*) - COUNT(' || column_name::TEXT || ') AS ' || column_name::TEXT, ','
            )
    FROM (
        /* Подзапрос для получения всех имен колонок из таблицы sales_import */
        SELECT column_name
            FROM information_schema.columns
            WHERE
                table_name = 'sales_import'
            ) AS c;

    -- Создаем временную таблицу,
    -- где в качестве столбцов будут строки из переменной COLS (названия столбцов с подсчетом NULL)
    EXECUTE format(
            'CREATE TEMP TABLE temp_counter AS SELECT %s FROM sales_import;',
            cols
            );

END $$;

SELECT * FROM temp_counter;  -- Вывод данных из временной таблицы
```

![](img/img_58.png)

**Результат:** мы получили количество null-значений по каждому столбцу нашей таблицы.

На основе этих данных можно сделать следующие выводы:

- по полям **img**, **title**, **console**, **genre**, **publisher** - качество набора данных хорошее, т.к. отсутствуют null-значения;
- по полям ***_sales**, **critic_score**, **last_update** - качество набора данных слабое;
- в большинстве случаев дата выхода игры заполнена, что позволит нам построить временной ряд выпуска игр и выбрать правильный диапазон для дальнейшего исследования. 

Избавимся от null-значений путём установки новых значений:

- для данных о количестве продаж (*_sales) и critic_score заменим null-значения на 0;
- для release_date и last_update установим дату по умолчанию '1900-01-01';
- для неизвестных разработчиков установим значение '--UNKNOWN--'.

```postgresql
/*
    Очистка null-значений 
*/
UPDATE sales_import
SET 
    total_sales = COALESCE(total_sales, 0),
    na_sales = COALESCE(na_sales, 0),
    jp_sales = COALESCE(jp_sales, 0),
    pal_sales = COALESCE(pal_sales, 0),
    other_sales = COALESCE(other_sales, 0),
    critic_score = COALESCE(critic_score, 0),
    release_date = COALESCE(release_date, '1900-01-01'),
    last_update = COALESCE(last_update, '1900-01-01'),
    developer = COALESCE(developer, '--UNKNOWN--');
```

![](img/img_59.png)

**Результат:** Данные обновились новыми значениями.

Снова выполним запрос на подсчет количества NULL-значений по каждому столбцу.

![](img/img_60.png)

**Результат:** NULL-значения в таблице отсутствуют. Можем приступать к нормализации базы таблицы SALES_IMPORT и проектированию базы данных SALES.

## Проектирование и создание целевой базы данных

### Задание 5: Нормализация базы данных

#### Определение сущностей

На основе анализа таблицы SALES_IMPORT можно выделить следующие основные сущности:

```
- 'games' (Игры)
- 'consoles' (Консоли)
- 'genres' (Жанры)
- 'publishers' (Издатели)
- 'developers' (Разработчики)
```

#### Определение связей

Для обеспечения целостности данных и логического моделирования сущностей, определим связи между указанными сущностями:

* **Игры** доступны на нескольких **Консолях** (M:N)
* **Жанр** содержит множество **Игр** (1:N)
* **Издатель** выпускает **Игры** (1:N)
* **Разработчик** создает **Игры** (1:N)

#### Определение атрибутов

Определим основные атрибуты для каждой сущности, чтобы нормализовать базу данных:

| **Сущность 'games' (Игры)**                                                              |
|------------------------------------------------------------------------------------------|
| **id** (PK): уникальный идентификатор игры                                               |
| **title**: название игры                                                                 |
| **img**: обложка игры                                                                    |
| **console_id** (FK): идентификатор консоли игры                                          |
| **genre_id** (FK): идентификатор жанра игры                                              |
| **publisher_id** (FK): идентификатор издателя игры                                       |
| **developer_id** (FK): идентификатор разработчика игры                                   |
| **release_date**: дата выхода игры                                                       |
| **critic_score**: оценка критиков                                                        |
| **total_sales**: количество продаж во всем мире (в миллионах экземпляров)                |
| **na_sales**: количество продаж в Северной Америке (в миллионах экземпляров)             |
| **jp_sales**: количество продаж в Японии (в миллионах экземпляров)                       |
| **pal_sales**: количество продаж в странах PAL: Европа, Африка (в миллионах экземпляров) |
| **other_sales**: количество продаж в других регионах (в миллионах экземпляров)           |
| **last_update**: дата последнего обновления данных                                       |

| **Сущность 'consoles' (Консоли)**             |
|-----------------------------------------------|
| **id** (PK): уникальный идентификатор консоли |
| **name**: название консоли                    |

| **Сущность 'genres' (Жанры)**               |
|---------------------------------------------|
| **id** (PK): уникальный идентификатор жанра |
| **name**: название жанра                    |

| **Сущность 'publishers' (Издатели)**           |
|------------------------------------------------|
| **id** (PK): уникальный идентификатор издателя |
| **name**: название издателя                    |

| **Сущность 'developers' (Разработчики)**           |
|----------------------------------------------------|
| **id** (PK): уникальный идентификатор разработчика |
| **name**: название разработчика                    |

### Создание и наполнение целевой базы данных

#### Вычисление длины текстовых полей

Вычислим длины текстовых полей для использования в атрибутах сущностей. Длина текстового поля атрибута будет равна максимального значения длины этого поля в таблице SALES_IMPORT с коэффициентом 1.5 и округление до положительного числа.

```postgresql
/*
    Определение длины полей для текстовых значений:
    Максимальная длина поля * 1.5
*/
SELECT 
    ROUND(MAX(LENGTH(title)) * 1.5) AS max_title_length,
	ROUND(MAX(LENGTH(img)) * 1.5) AS max_img_length,
	ROUND(MAX(LENGTH(console)) * 1.5) AS max_console_length,
    ROUND(MAX(LENGTH(genre)) * 1.5) AS max_genre_length,
    ROUND(MAX(LENGTH(publisher)) * 1.5) AS max_publisher_length,
    ROUND(MAX(LENGTH(developer)) * 1.5) AS max_developer_length
FROM sales_import;
```

![](img/img_61.png)

**Результат:** определили длину текстовых полей атрибутов. Все поля уклыдываются в длину VARCHAR(255), поэтому будем ее использовать при определении длины текстовых полей. 

#### Создание и наполнение справочников

Создадим таблицы для справочников 'consoles' (Консоли), 'genres' (Жанры), 'publishers' (Издатели), 'developers' (Разработчики) предварительно удалив одноименные таблицы (если такие существуют):

```postgresql
/* Удаление таблиц справочников */
DROP TABLE IF EXISTS consoles;  -- Удаление таблицы сущности 'consoles' (Консоли)
DROP TABLE IF EXISTS genres;  -- Удаление таблицы сущности 'genres' (Жанры)
DROP TABLE IF EXISTS publishers;  -- Удаление таблицы сущности 'publishers' (Издатели)
DROP TABLE IF EXISTS developers;  -- Удаление таблицы сущности 'developers' (Разработчики)

/* Создание таблицы для сущности 'consoles' (Консоли) */
CREATE TABLE consoles (
    id SMALLSERIAL PRIMARY KEY,     -- Уникальный идентификатор консоли
    name VARCHAR(255) NOT NULL      -- Название консоли
);

/* Создание таблицы для сущности 'genres' (Жанры) */
CREATE TABLE genres (
    id SMALLSERIAL PRIMARY KEY,     -- Уникальный идентификатор жанра
    name VARCHAR(255) NOT NULL      -- Название жанра
);

/* Создание таблицы для сущности 'publishers' (Издатели) */
CREATE TABLE publishers (
    id SMALLSERIAL PRIMARY KEY,     -- Уникальный идентификатор издателя
    name VARCHAR(255) NOT NULL      -- Название издателя
);

/* Создание таблицы для сущности 'developers' (Разработчики) */
CREATE TABLE developers (
    id SMALLSERIAL PRIMARY KEY,     -- Уникальный идентификатор разработчика
    name VARCHAR(255) NOT NULL      -- Название разработчика
);
```

![](img/img_62.png)

**Результат:** таблицы справочников успешно созданы.

Заполняем данные в справочниках:

```postgresql
/*
    Заполнение таблицы-справочника 'consoles' (Консоли)
    и проверка заполнения таблицы
*/
INSERT INTO consoles(name)
    SELECT DISTINCT console
    FROM sales_import;

SELECT * FROM consoles;
```

![](img/img_63.png)

```postgresql
/*
    Заполнение таблицы-справочника 'genres' (Жанры)
    и проверка заполнения таблицы
*/
INSERT INTO genres(name)
    SELECT DISTINCT genre
    FROM sales_import;

SELECT * FROM genres;
```

![](img/img_64.png)

```postgresql
/*
    Заполнение таблицы-справочника 'publishers' (Издатели)
    и проверка заполнения таблицы
*/
INSERT INTO publishers(name)
    SELECT DISTINCT publisher
    FROM sales_import;

SELECT * FROM publishers;
```

![](img/img_65.png)

```postgresql
/*
    Заполнение таблицы-справочника 'developers' (Разработчики)
    и проверка заполнения таблицы
*/
INSERT INTO developers(name)
    SELECT DISTINCT developer
    FROM sales_import;

SELECT * FROM developers;
```

![](img/img_66.png)

**Результат:** мы создали таблицы справочников и заполнили их уникальными значениями из таблицы **SALES_IMPORT**. Теперь можем приступать к созданию и заполнению таблицы **GAMES**.

#### Создание и наполнение таблицы игр

Создадим таблицу для сущности 'games' (Игры):

```postgresql
/* Создание таблицы для сущности 'games' (Игры) */
CREATE TABLE games (
    id SERIAL PRIMARY KEY,                                  -- Уникальный идентификатор игры
    title VARCHAR(255) NOT NULL,                            -- Название игры
    img VARCHAR(255) DEFAULT NULL,                          -- Обложка игры
    console_id INT NOT NULL REFERENCES consoles(id),        -- Идентификатор консоли (FK)
    genre_id INT NOT NULL REFERENCES genres(id),            -- Идентификатор жанра (FK)
    publisher_id INT NOT NULL REFERENCES publishers(id),    -- Идентификатор издателя (FK)
    developer_id INT NOT NULL REFERENCES developers(id),    -- Идентификатор разработчика (FK)
    release_date DATE DEFAULT '1900-01-01',                 -- Дата выхода игры                                                       |
    critic_score DECIMAL(4, 2) DEFAULT 0,                   -- Оценка критиков (например, 8.75)
    total_sales DECIMAL(10, 2) DEFAULT 0,                   -- Количество продаж во всем мире (в миллионах экземпляров)
    na_sales DECIMAL(10, 2) DEFAULT 0,                      -- Количество продаж в Северной Америке (в миллионах экземпляров)
    jp_sales DECIMAL(10, 2) DEFAULT 0,                      -- Количество продаж в Японии (в миллионах экземпляров)
    pal_sales DECIMAL(10, 2) DEFAULT 0,                     -- Количество продаж в странах PAL (в миллионах экземпляров)
    other_sales DECIMAL(10, 2) DEFAULT 0,                   -- Количество продаж в других регионах (в миллионах экземпляров)
    last_update DATE DEFAULT '1900-01-01'                   -- Дата последнего обновления данных
);
```

Заполним таблицу **GAMES** данными из таблицы **SALES_IMPORT** и проверим ее заполнение:

```postgresql
/*
    Заполнение и проверка заполнения таблицы 'games' (Игры)
*/
INSERT INTO games (
                   title,
                   img,
                   console_id,
                   genre_id,
                   publisher_id,
                   developer_id,
                   release_date,
                   critic_score,
                   total_sales,
                   na_sales,
                   jp_sales,
                   pal_sales,
                   other_sales,
                   last_update)
SELECT
    title,
    img,
    (SELECT id FROM consoles WHERE name = console) AS console_id,
    (SELECT id FROM genres WHERE name = genre) AS genre_id,
    (SELECT id FROM publishers WHERE name = publisher) AS publisher_id,
    (SELECT id FROM developers WHERE name = developer) AS developer_id,
    TO_DATE(release_date, 'YYYY-MM-DD'),
    critic_score,
    total_sales,
    na_sales,
    jp_sales,
    pal_sales,
    other_sales,
    TO_DATE(last_update, 'YYYY-MM-DD')
FROM sales_import;

SELECT * FROM games;
```

![](img/img_67.png)

**Результат:** мы создали таблицу GAMES и заполнили ее данными из таблицы **SALES_IMPORT** в соответствии с правилами нормализации. Теперь можем приступать к выборке необходимых данных для достижения цели итогового проекта.

#### Построение словаря данных для базы данных SALES

Словарь данных — это систематизированная информация о структуре таблиц в базе данных, включая их поля и типы данных.

Построим словарь данных для базы данных SALES, чтобы убедиться, что все сущности и атрибуты созданы:

```postgresql
/* Строим словарь данных базы данных SALES */
SELECT
    c.relname as "Таблица",     -- Название таблицы
    a.attnum as "№ п/п",        -- Номер столбца в таблице
    a.attname as "Поле",        -- Название столбца
    pt.typname as "Тип",        -- Тип данных для столбца
    CASE                        -- Определяем размер поля
        WHEN a.atttypmod = -1
            THEN NULL
        ELSE a.atttypmod
    END "Размер",
    a.attnotnull as "NULL",     -- Допускаются ли NULL-значения в поле
    CASE                        -- Является ли поле первичным ключом (PK)
        WHEN a.attnum IN(
        SELECT UNNEST(cn.conkey)
        FROM
            pg_catalog.pg_constraint cn
        WHERE
            cn.conrelid = a.attrelid
          AND cn.contype LIKE 'p')
            THEN 'PK'
    END as "Ключ"
FROM
  pg_catalog.pg_attribute a  -- Информация об атрибутах (полях) таблиц
  JOIN pg_catalog.pg_type pt ON a.atttypid = pt.oid  -- Информация о типах данных
  JOIN pg_catalog.pg_class c ON a.attrelid = c.oid  -- Информация о таблицах
  JOIN pg_catalog.pg_namespace n ON c.relnamespace = n.oid  -- Информация о схемах
  LEFT JOIN pg_catalog.pg_description ad ON ad.objoid = a.attrelid  -- Комментарии к объектам
  AND ad.objsubid = a.attnum
WHERE
  a.attnum > 0  -- Убираем системные поля (нумерация атрибутов начинается с 1)
  AND n.nspname = 'public'  -- Ограничиваем выборку только таблицами из схемы public
  and c.reltype <> 0  -- Убираем не-пользовательские объекты из выборки
ORDER BY
  c.relname,  -- Сортируем результат по названию таблицы...
  a.attnum;   -- ... и по номеру атрибута
```
![](img/img_68.png)

**Результат:** Словарь данных для базы данных SALES успешно построен. Все необходимые сущности, атрибуты и связи присутствуют. На основе этих данных построим логическую схему базы данных SALES. 

### Задание 6: Создание логической диаграммы

Исходя из созданных сущностей, связей и атрибутов сформируем инфологическую диаграмму основных сущностей по нотации Чана:

![](img/EXAM_FINAL_DB_model.jpg)

## Анализ ключевых факторов, влияющих на успех разработки компьютерной игры

### Задание 7: Удаление малозначительных данных

Удалим из таблицы **GAMES** малозначительных игр (у которых total_sales < 0.5 и critic_score <= 0):

```postgresql
/*
    Удаление малозначимых игр,
    у которых total_sales < 0.5 и critic_score <= 0
 */
DELETE FROM games
WHERE
    total_sales < 0.5 OR
    critic_score <= 0;
```

![](img/img_69.png)

![](img/img_70.png)

**Результат:** Малозначительные игры удалены из таблицы GAMES.

Вычислим качество набора данных - сколько процентов записей от первоначального
объема осталось?

```postgresql
/*
    Вычисление качества набора данных
    Сколько процентов записей от первоначального количества (64016) осталось
*/
SELECT
    ROUND((COUNT(title)::DECIMAL / 64016) * 100, 2) || '%' AS quality_db
FROM
    games;
```

![](img/img_71.png)

**Результат:** от первоначального количества (64016 записей) осталось 2,37% записей, что говорит о слабом качестве набора данных.

### Задание 8: Выбор временного интервала для исследования

Определим глобальные продажи игр за каждый год, чтобы выбрать оптимальный период для исследования:

```postgresql
/*
    Распределение глобальных продаж игр по времени
*/
SELECT
    EXTRACT(YEAR FROM release_date) AS year,
    SUM(total_sales) AS total_sales
    FROM
        games
    GROUP BY
        year
    ORDER BY
        year ASC;
```

![](img/img_72.png)

Средствами pAdmin построим график распределения глобальных продаж по годам для лучшей визуализации:

![](img/img_73.png)

**Результат:** данные представлены на временном отрезке с 1989 года по 2018 год. Интерес для нас может представлять временной отрезов с 2004 по 2018 год, что соответствует данным за 20 лет. 

### Задание 9: Вывод ТОП-100 игр по количеству проданных экземпляров

Найдем ТОП-100 игр по количеству проданных экземпляров и покажем в виде представления:

```postgresql
/*
    Создание представления (view) "ТОП-100 игр" по количеству продаж
*/
DROP VIEW IF EXISTS top_100_games_by_sales;  -- Удаление представления (если существует)

CREATE VIEW top_100_games_by_sales AS  -- Создание представления
SELECT
	g.title,
	c.name AS console,
	j.name AS genre,
	p.name AS publisher,
	d.name AS developer,
	SUM(g.total_sales) AS total_sales,
	EXTRACT(YEAR FROM g.release_date) AS release_year
FROM games g
JOIN consoles c ON g.console_id = c.id
JOIN genres j ON g.genre_id = j.id
JOIN publishers p ON g.publisher_id = p.id
JOIN developers d ON g.developer_id = d.id
WHERE g.release_date >= NOW() - INTERVAL '20 years'
GROUP BY g.title, c.name, j.name, p.name, d.name, g.release_date
ORDER BY total_sales DESC
LIMIT 100;

SELECT * FROM top_100_games_by_sales;  -- Отображение представления
```

![](img/img_74.png)

![](img/img_77.png)

**Результат:** за выбранный 20-ти летний период самая популярная игра - это "Grand Theft Auto V" на платформе "PS3", которая была продана в количестве 20,32 млн. экземпляров.

### Задание 10: Вывод ТОП-100 игр по оценке критиков

Найдем какие игры выше всего оценены критиками в представлении ТОП-100 игр за выбранный временной период (20 лет):

```postgresql
/*
    Создание представления (view) "ТОП-100 игр" по количеству оценок критиков (среднее значение)
*/

DROP VIEW IF EXISTS top_100_games_by_critics;  -- Удаление представления (если существует)

CREATE VIEW top_100_games_by_critics AS  -- Создание представления
SELECT
	g.title,
	c.name AS console,
	j.name AS genre,
	p.name AS publisher,
	d.name AS developer,
	ROUND(AVG(g.critic_score), 2) AS critic_score,
	EXTRACT(YEAR FROM g.release_date) AS release_year
FROM games g
JOIN consoles c ON g.console_id = c.id
JOIN genres j ON g.genre_id = j.id
JOIN publishers p ON g.publisher_id = p.id
JOIN developers d ON g.developer_id = d.id
WHERE g.release_date >= NOW() - INTERVAL '20 years'
GROUP BY g.title, c.name, j.name, p.name, d.name, g.release_date
ORDER BY critic_score DESC
LIMIT 100;

SELECT * FROM top_100_games_by_critics;  -- Отображение представления
```

![](img/img_74.png)

![](img/img_78.png)

**Результат:** за выбранный 20-ти летний период самые популярные игры по оценкам критиков - это "Red Dead Redemption: Undead Nightmare" (на платформах X360 и PS3) и "Grand Theft Auto IV" (на платформах X360 и PS3) с максимальной оценкой 10.0 баллов.

### Задание 11: Поиск пересечения полученных результатов

Найдем пересечение полученных двух предыдуших результатов и сохраним результат как материализованное представление:

```postgresql
/*
    Создание материализованного представления по 2 представлениям
*/
-- Удаляем мат. представление, если существует
DROP MATERIALIZED VIEW IF EXISTS top_100_games_join;

-- Создаём мат. представление
CREATE MATERIALIZED VIEW top_100_games_join AS
SELECT
    v1.title,
    v1.console,
	v1.genre,
	v1.publisher,
	v1.developer
FROM
    top_100_games_by_sales v1  -- Представление по количеству продаж
INTERSECT
SELECT
    v2.title,
    v2.console,
	v2.genre,
	v2.publisher,
	v2.developer
FROM
    top_100_games_by_critics v2;  -- Представление по оценкам критиков

-- Вывод мат. представления
SELECT * FROM top_100_games_join;
```

![](img/img_79.png)

**Результат:** найдено 33 пересечения - игры, которые имеют высокие продажи и высоко оценены критиками.

### Задание 12: Какая консоль самая популярная у игр с высокими продажами и оценками критиков

Найдем в нашем материализованном запросе популярные консоли:

```postgresql
/*
    Поиск популярной консоли 
*/
SELECT
	console,
	COUNT(console) AS console_count
	FROM
		top_100_games_join
	GROUP BY
		console
	ORDER BY console_count DESC;
```

![](img/img_80.png)

**Результат:** самыми популярными консолями для игр с высокими продажами и оценками критиков являются **X360**, **PS3**, **PS4**, но так как набор данных бедный и сейчас уже популярна версия PS5, то лучше вести кросс-платформенную разработку игры как для Xbox, так и для PlayStation.

### Выбор успешного издателя

Определим из материализованного представления самого успешного издателя:

```postgresql
/*
    Поиск самого успешного издателя
*/
SELECT
	publisher,
	COUNT(publisher) AS publisher_count
	FROM
		top_100_games_join
	GROUP BY
		publisher
	ORDER BY publisher_count DESC;
```

![](img/img_81.png)

**Результат:** издательствами, которые разрабатывают самые продаваемые игры с высокими оценками экспертов являются **Rockstar Games** и **Activision** (принадлежит Microsoft). К ним следует обратиться в первую очередь для дистрибуции разрабатываемой игры. 

Посчитаем кто из издателей регулярно выпускает игры, то есть за 20 лет выпустил не менее 20 игр и определим соотношение выпущенных игр и количеству их продаж (rate), чтобы определить, кто из издателей умеет грамотно выпускать игры с высокими продажами:

```postgresql
/*
    Поиск популярного издателя по коэффициенту:
    количество продаж / игра
*/
SELECT
	p.name AS publisher,  -- наименование издателя
	SUM(g.total_sales) AS total_sales,  -- кол-во продаж
	COUNT(g.title) AS games_count,  -- кол-во игр
	ROUND(AVG(g.critic_score), 2) AS critic_score_avg,  -- средняя оценка критиков
	ROUND(SUM(g.total_sales) / COUNT(g.title), 2) AS rate  -- коэффициент ПРОДАЖИ / ИГРЫ
	FROM games g
	JOIN publishers p ON g.publisher_id = p.id
	WHERE
		release_date >= NOW() - INTERVAL '20 years'  -- интервал: 20 лет
	GROUP BY
		p.name
	HAVING
		COUNT(g.title) >= 20 -- не менее 20 игр 
	ORDER BY
		rate DESC  -- сортируем по коэффициенту
	LIMIT 10;  -- ТОП-10 издателей
```

![](img/img_82.png)

**Результат:** издатели **Rockstar Games** и **Activision** снова лидируют. Остальных издателей также возьмем на вооружение как эффективных.

### Выбор перспективного жанра

Найдем ТОП-10 популярных жанров игры за последние 20 лет:

````postgresql
/*
    Поиск популярного жанра игры: ТОП-10
*/
SELECT
	j.name AS genre,
	SUM(g.total_sales) AS total_sales
	FROM games g
	JOIN genres j ON g.genre_id = j.id
	WHERE
		release_date >= NOW() - INTERVAL '20 years'
	GROUP BY
		genre
	ORDER BY
		total_sales DESC
	LIMIT 10;
````

![](img/img_83.png)

**Результат:** самыми популярными жанрами игр за последние 20 лет являются: **Shooter**, **Action** и **Sport**.

### Выбор названия игры

Для выбора названия игры определим самые популярные слова в названиях игр. Эти слова мы не будем использовать в названии нашей игры:

```postgresql
WITH word_list AS (SELECT unnest(string_to_array(lower(title), ' ')) AS word
                   FROM games)  -- строим массив слов из всех названий игр
SELECT word,
       COUNT(*) AS count
FROM word_list
WHERE word <> '' -- Исключаем пустые слова
  AND LENGTH(word) > 3  -- длина слова: более 3 символов
GROUP BY word
ORDER BY count DESC
LIMIT 10;  -- Ограничиваем выборку наиболее частыми словами (например, 10)
```

![](img/img_84.png)

**Результат:** эти слова желательно не использовать в названии разрабатываемой игры, так как они, возможно, будут у участников ассоциироваться с названиями других игр и продвижение в интернет по ключевым словам будет затруднено:
* **lego**
* **call**
* **soccer**
* **madden**
* **fifa**
* **star**
* **need**
* **duty**
* **game**
* **wars**

### Выбор рынка для выпуска игры

Выберем рынок на котором мы сможем выпустить игру:

```postgresql
/*
    Выбор рынка игры
*/
SELECT
	SUM(na_sales) AS "North America",
	SUM(jp_sales) AS Japan,
	SUM(pal_sales) AS Europe,
	SUM(other_sales) AS Other
	FROM games;
```

![](img/img_85.png)

**Результат:** наиболее интересны для выпуска игры для нас будут "англоговорящие" регионы **North America** и **Europe**.  

### Задание 12: Определение наиболее перспективной серии игр

Так как у нас данных в представлении **top_100_games_join** не много, то мы можем определить наиболее перспективную серию игр:

```postgresql
/*
    Определение наиболее перспективной серии игр:
    извлекаем первые слова из названия и считаем их встречаемость в названии
*/
SELECT 
    SUBSTRING(title FROM '^[^ ]+') AS first_word,   -- Извлекаем первое слово из названия
    COUNT(*) AS game_count,                         -- Считаем количество игр
    ARRAY_AGG(title) AS titles                      -- Собираем названия игр в массив
FROM 
    top_100_games_join
GROUP BY 
    first_word                                      -- Группируем по первому слову
HAVING 
    COUNT(*) > 1                                    -- Отбираем группы, где более одной строки
ORDER BY 
    game_count DESC, first_word;                    -- Сортируем по встречаемости игр и первому слову
```

![](img/img_86.png)

**Результат:** наиболее перспективными сериями игр являются серии игр **Call of Duty** и **Grand Theft Auto** - по ним больше всего успешных и продаваемых версий.

Проверяем:

```postgresql
/*
    Проверка количества серий игр
*/
SELECT title, console FROM top_100_games_join ORDER BY title;
```

![](img/img_87.png)

**Результат:** мы подтвердили, что наиболее перспективными сериями игр являются серии игр **Call of Duty** и **Grand Theft Auto**, т.к. уже выпущено несколько версий игры и версии игры представлены на разных платформах (консолях).

## Основные выводы и рекомендации

В результате проведенного исследования можно выделить несколько ключевых выводов, которые подчеркивают перспективность и целесообразность разработки новых игр в условиях рынка 2025 года:

1. [Наиболее перспективными сериями игр](#задание-12-определение-наиболее-перспективной-серии-игр), на которые можно ориентироваться при дальнейшей разработке, являются **Call of Duty** и **Grand Theft Auto**. Эти франшизы уже зарекомендовали себя на рынке и имеют стабильную аудиторию.
2. [Наиболее привлекательными регионами](#выбор-рынка-для-выпуска-игры) для выпуска новой игры являются англоговорящие регионы **North America** и **PAL**. Эти рынки предлагают широкий потенциал для роста и развития.
3. Важно избегать использования популярных [слов-паразитов](#выбор-названия-игры) в названиях игры, таких как **lego**, **call**, **soccer**, **madden**, **fifa**, **star**, **need**, **duty**, **game**, **wars**, чтобы обеспечить оригинальность и привлекательность игры.
4. Разработка игры должна сосредоточиться на таких [жанрах](#выбор-перспективного-жанра), как **Shooter**, **Action** или **Sport**, так как они демонстрируют высокие показатели продаж и интереса со стороны игроков. 
5. Для дистрибуции игры целесообразно сотрудничать с [признанными и успешными издателями](#выбор-успешного-издателя), такими как **Rockstar Games** и **Activision**, которые уже зарекомендовали себя на рынке и могут гарантировать успешный запуск новой игры.
6. Разработка новой игры рекомендуется вести для [консольных платформ](#задание-12-какая-консоль-самая-популярная-у-игр-с-высокими-продажами-и-оценками-критиков) **X360**, **PS3**, **PS4** и их современных аналогов, так как они продемонстрировали высокие продажи и положительные отзывы критиков.
7. Исследование проводилось в рамках [двадцатилетнего временного интервала](#задание-8-выбор-временного-интервала-для-исследования), что позволило получить объективные результаты и рекомендации для будущих разработок.

Таким образом, цели и задачи проекта были успешно достигнуты, что подтверждает актуальность и значимость полученных выводов для дальнейших исследований и практической деятельности в области разработки видеоигр.

### Направления дальнейших исследований

На основе проекта можно выделить следующие направления для дальнейших исследований:

1. **Анализ трендов в развитии серий игр:** Исследовать эволюцию серий **Call of Duty** и **Grand Theft Auto** для выявления ключевых факторов успеха в различных временных промежутках.
2. **Изучение рынка англоговорящих регионов:** Составить детализированное демографическое исследование игроков в **North America** и **PAL** для анализа предпочтений, возрастания интереса и вовлеченности пользователей.
3. **Определение факторов, влияющих на выбор названия игры:** Провести анализ на основе текстов названий игр для выявления частоты использования слов-паразитов и их влияния на успех игры.
4. **Проведение жанрового анализа:** Провести анализ данных о продажах и отзывах игр в жанрах **Shooter**, **Action** и **Sport** с целью выявления самых успешных поджанров и механик.
5. **Оценка популярных игровых платформ:** Провести исследование, сравнивающее эффективность дистрибуции игр на консолях **X360**, **PS3**, **PS4** и их современных продолжениях, включая данные о продажах и оценках критиков.
6. **Сравнение успеха различных издателей:** Исследовать, как издательская политика **Rockstar Games** и **Activision** (Microsoft) влияет на успех игр.
7. **Изучение исторического контекста игровых трендов:** Сравнить изменения в предпочтениях игроков за последние 20 лет с изученем изменений в жанрах, механиках и культурных особенностей.
8. **Анализ влияния маркетинговых кампаний:** Исследовать, как маркетинговые стратегии влияют на успех релиза игры с анализом данных о расходах на рекламу и результатах продаж.
9. **Определение характеристик успешных игр:** Провести анализ характеристик (графика, механика, сюжет) и их корреляции с успехом игры на рынке.
10. **Прогнозирование будущих трендов в игровой индустрии:** Построить модели на основе имеющихся данных с прогнозированием изменений и новых направлений в видеоигровой индустрии на основе текущих тенденций.

Эти направления могут создать прочную основу для глубоких исследований и расширения знаний в области игровой индустрии.

## Приложение 1. Создание триггера для отслеживания данных в таблице GAMES

Отслеживание изменений в таблице **GAMES** позволит вести аудит изменений, что бывает полезно для обеспечения целостности данных и анализа их истории.

### Создание таблицы для отслеживания изменений

Создадим таблицу для хранения старых и новых значений в таблице GAMES, времени изменения:

```postgresql
/*
    Создание таблицы для отслеживания изменений в таблице GAMES
*/
DROP TABLE IF EXISTS change_log_tbl_games;  -- Удаление таблицы (если существует)

-- Создание таблицы
CREATE TABLE change_log_tbl_games (
    id SERIAL PRIMARY KEY,
    game_id INT REFERENCES games(id) ON DELETE CASCADE,  -- Ссылка на таблицу игр с каскадным удалением

    old_title VARCHAR(255),  -- Название игры
    new_title VARCHAR(255),

    old_console_id INT,  -- Идентификатор консоли (FK)
    new_console_id INT,

    old_genre_id INT,  -- Идентификатор жанра (FK)
    new_genre_id INT,

    old_publisher_id INT,  -- Идентификатор издателя (FK)
    new_publisher_id INT,

    old_developer_id INT,  -- Идентификатор разработчика (FK)
    new_developer_id INT,

    old_img VARCHAR(255),  -- Обложка игры
    new_img VARCHAR(255),

    old_release_date DATE,  -- Дата выхода игры
    new_release_date DATE,

    old_critic_score DECIMAL(4, 2),  -- Оценка критиков
    new_critic_score DECIMAL(4, 2),

    old_total_sales DECIMAL(10, 2),  -- Количество продаж во всем мире (в миллионах экземпляров)
    new_total_sales DECIMAL(10, 2),

    old_na_sales DECIMAL(10, 2),  -- Количество продаж в Северной Америке (в миллионах экземпляров)
    new_na_sales DECIMAL(10, 2),

    old_jp_sales DECIMAL(10, 2),  -- Количество продаж в Японии (в миллионах экземпляров)
    new_jp_sales DECIMAL(10, 2),

    old_pal_sales DECIMAL(10, 2),  -- Количество продаж в странах PAL (в миллионах экземпляров)
    new_pal_sales DECIMAL(10, 2),

    old_other_sales DECIMAL(10, 2),  -- Количество продаж в других регионах (в миллионах экземпляров)
    new_other_sales DECIMAL(10, 2),

    old_last_update DATE,  -- Дата последнего обновления данных
    new_last_update DATE,

    change_time TIMESTAMP DEFAULT CURRENT_TIMESTAMP
);

SELECT * FROM change_log_tbl_games; -- Проверка создания таблицы изменений
```

**Результат:** таблица изменений CHANGE_LOG_TBL_GAMES успешно создана.

### Создание функции триггера

Теперь создадим функцию, которая будет вызываться при каждом изменении записи в таблице GAMES. Эта функция будет добавлять запись в таблицу CHANGE_LOG_TBL_GAMES:

```postgresql
CREATE OR REPLACE FUNCTION log_changes_tbl_games() 
RETURNS TRIGGER AS $$
BEGIN
    -- Проверяем, изменились ли какие-либо из полей:
    IF (NEW.title IS DISTINCT FROM OLD.title) THEN
        INSERT INTO change_log_tbl_games (game_id, old_title, new_title)
        VALUES (OLD.id, OLD.title, NEW.title);
    END IF;

    IF (NEW.console_id IS DISTINCT FROM OLD.console_id) THEN
        INSERT INTO change_log_tbl_games (game_id, old_console_id, new_console_id)
        VALUES (OLD.id, OLD.console_id, NEW.console_id);
    END IF;

    IF (NEW.genre_id IS DISTINCT FROM OLD.genre_id) THEN
        INSERT INTO change_log_tbl_games (game_id, old_genre_id, new_genre_id)
        VALUES (OLD.id, OLD.genre_id, NEW.genre_id);
    END IF;
    
    IF (NEW.publisher_id IS DISTINCT FROM OLD.publisher_id) THEN
        INSERT INTO change_log_tbl_games (game_id, old_publisher_id, new_publisher_id)
        VALUES (OLD.id, OLD.publisher_id, NEW.publisher_id);
    END IF;

    IF (NEW.developer_id IS DISTINCT FROM OLD.developer_id) THEN
        INSERT INTO change_log_tbl_games (game_id, old_developer_id, new_developer_id)
        VALUES (OLD.id, OLD.developer_id, NEW.developer_id);
    END IF;

	IF (NEW.img IS DISTINCT FROM OLD.img) THEN
        INSERT INTO change_log_tbl_games (game_id, old_img, new_img)
        VALUES (OLD.id, OLD.img, NEW.img);
    END IF;

	IF (NEW.release_date IS DISTINCT FROM OLD.release_date) THEN
        INSERT INTO change_log_tbl_games (game_id, old_release_date, new_release_date)
        VALUES (OLD.id, OLD.release_date, NEW.release_date);
    END IF;

	IF (NEW.critic_score IS DISTINCT FROM OLD.critic_score) THEN
        INSERT INTO change_log_tbl_games (game_id, old_critic_score, new_critic_score)
        VALUES (OLD.id, OLD.critic_score, NEW.critic_score);
    END IF;

	IF (NEW.total_sales IS DISTINCT FROM OLD.total_sales) THEN
        INSERT INTO change_log_tbl_games (game_id, old_total_sales, new_total_sales)
        VALUES (OLD.id, OLD.total_sales, NEW.total_sales);
    END IF;

	IF (NEW.na_sales IS DISTINCT FROM OLD.na_sales) THEN
        INSERT INTO change_log_tbl_games (game_id, old_na_sales, new_na_sales)
        VALUES (OLD.id, OLD.na_sales, NEW.na_sales);
    END IF;

	IF (NEW.jp_sales IS DISTINCT FROM OLD.jp_sales) THEN
        INSERT INTO change_log_tbl_games (game_id, old_jp_sales, new_jp_sales)
        VALUES (OLD.id, OLD.jp_sales, NEW.jp_sales);
    END IF;

	IF (NEW.pal_sales IS DISTINCT FROM OLD.pal_sales) THEN
        INSERT INTO change_log_tbl_games (game_id, old_pal_sales, new_pal_sales)
        VALUES (OLD.id, OLD.pal_sales, NEW.pal_sales);
    END IF;

	IF (NEW.other_sales IS DISTINCT FROM OLD.other_sales) THEN
        INSERT INTO change_log_tbl_games (game_id, old_other_sales, new_other_sales)
        VALUES (OLD.id, OLD.other_sales, NEW.other_sales);
    END IF;

	IF (NEW.last_update IS DISTINCT FROM OLD.last_update) THEN
        INSERT INTO change_log_tbl_games (game_id, old_last_update, new_last_update)
        VALUES (OLD.id, OLD.last_update, NEW.last_update);
    END IF;

    RETURN NEW; -- Возвращаем новые значения
END;
$$ LANGUAGE plpgsql;
```

![](img/img_88.png)

![](img/img_89.png)

**Результат:** Функция триггера создана успешно.

### Создание триггера

Создадим триггер, который будет вызывать функцию при каждом обновлении записи в таблице GAMES:

```postgresql
-- Удаляем триггер (если он существует)
DROP TRIGGER IF EXISTS trigger_changes_log_tbl_games ON games;

-- Создаем триггер
CREATE TRIGGER trigger_changes_log_tbl_games
AFTER UPDATE ON games
FOR EACH ROW
EXECUTE PROCEDURE log_changes_tbl_games();
```

![](img/img_90.png)

![](img/img_91.png)

**Результат:** Триггер, вызывающий функцию **log_changes_tbl_games()** при каждом обновлении записи в таблице **games**, успешно создан.

### Проверка работы триггера

Для проверки работы триггера создадим запись в таблице **games**, затем обновим её, чтобы триггер вызвал функцию и зафиксировал изменения в таблице **change_log_tbl_games**.

```postgresql
-- Удалим ранее созданные данные о тестовых играх
DELETE FROM games
WHERE title IN ('Updated: This is Test Game 1', 'Updated: This is Test Game 2');

-- Вставить новую запись в таблицу GAMES
INSERT INTO games (title, console_id, genre_id, publisher_id, developer_id, img, release_date, critic_score, total_sales, na_sales, jp_sales, pal_sales, other_sales, last_update)
VALUES
('This is Test Game 1', 1, 1, 1, 1, 'path/to/image1.jpg', '2020-01-01', 7.50, 10.50, 1.50, 3.20, 0.70, 6.10, CURRENT_DATE),
('This is Test Game 2', 2, 2, 2, 2, 'path/to/image2.jpg', '2022-12-31', 8.30, 23.40, 7.50, 3.99, 1.23, 0.73, CURRENT_DATE);

-- Проверим, что игры были добавлены
SELECT * FROM games WHERE title IN ('This is Test Game 1', 'This is Test Game 2');
```

![](img/img_92.png)

**Результат:** Тестовые игры добавлены в базу.

Обновим записи в таблице GAMES (вызовем триггер):

```postgresql
-- Обновляем записи в таблице GAMES (вызываем триггер)
UPDATE games
SET
    title = 'Updated: This is Test Game 1',
    console_id = 3,
    genre_id = 3,
    publisher_id = 3,
    developer_id = 3,
    img = 'path/to/new/image3.jpg',
    release_date = '2021-01-01',
    critic_score = 2.50,
    total_sales = 21.00,
    na_sales = 3.00,
    jp_sales = 6.40,
    pal_sales = 1.40,
    other_sales = 12.20,
    last_update = CURRENT_DATE
WHERE title = 'This is Test Game 1';

UPDATE games
SET
    title = 'Updated: This is Test Game 2',
    console_id = 4,
    genre_id = 4,
    publisher_id = 4,
    developer_id = 4,
    img = 'path/to/new/image4.jpg',
    release_date = '2019-12-31',
    critic_score = 5.10,
    total_sales = 46.80,
    na_sales = 15.00,
    jp_sales = 8.99,
    pal_sales = 2.46,
    other_sales = 1.50,
    last_update = CURRENT_DATE
WHERE title = 'This is Test Game 2';
```

**Результат:** данные по тестовым играм в таблице GAMES обновили, триггер вызвали.

Проверяем таблицу изменений:

```postgresql
-- Проверяем таблицу изменений
SELECT *
FROM change_log_tbl_games
WHERE game_id IN (
    SELECT id
    FROM games
    WHERE title IN ('Updated: This is Test Game 1', 'Updated: This is Test Game 2')
)
ORDER BY old_title;
```

![](img/img_93.png)

**Результат:** таблица изменений пополнилась новыми значениям с указанием предыдущих и новых значений таблицы GAMES. Одной записи в таблице изменений соответствует изменение одного значения для игры: title, console_id, img и другие. Триггер успешно работает.

## Приложение 2. Разворачивание Docker-контейнера с базой данных PostgreSQL для выполнения проекта

Важным шагом в обеспечении стабильной и удобной среды для разработки, тестирования и развертывания приложения для выполнения проекта является развертывание Docker-контейнера с базой данных PostgreSQL. Использование Docker позволяет изолировать среду выполнения, что гарантирует совместимость с различными системами и убирает зависимость от локальных установок. Это упрощает процесс настройки, так как все необходимые зависимости и конфигурации хранятся в одном контейнере. Это упрощает масштабирование и управление версиями базы данных. Благодаря этому можно сосредоточиться на написании кода, минимизируя время, затрачиваемое на настройку и диагностику проблем, связанных с окружением.

Файл docker-compose.yaml:

```dockerfile
services:
  postgres:
    container_name: postgres_server_container
    image: postgres:17.0
    environment:
      POSTGRES_DB: 'postgres'
      POSTGRES_USER: 'postgres'
      POSTGRES_PASSWORD: 'changeme'
      PGDATA: /var/lib/postgresql/data/pgdata
    volumes:
      - ./initdb:/docker-entrypoint-initdb.d
      - .:/var/lib/postgresql/data
    ports:
      - "5432:5432"
    restart: unless-stopped
    networks:
      - postgres

  pgadmin:
    container_name: pgadmin_container
    image: dpage/pgadmin4:8.12
    depends_on:
      - postgres
    environment:
      PGADMIN_DEFAULT_EMAIL: 'pgadmin@example.com'
      PGADMIN_DEFAULT_PASSWORD: 'admin'
      PGADMIN_CONFIG_SERVER_MODE: 'False'
    volumes:
      - ./pgadmin:/var/lib/pgadmin
    ports:
      - "5050:80"
    networks:
      - postgres
    restart: unless-stopped

networks:
    postgres:
        driver: bridge
```

### Доступ к Postgres:

- **URL:** `postgres:5432`
- **Username:** `postgres`
- **Password:** `changeme`

### Доступ к PgAdmin:

- **URL:** `http://localhost:5050`
- **E-mail:** `pgadmin@example.com`
- **Password:** `admin`

### Запуск и остановка Docker-проекта

```dockerfile
# Запуск Docker-проекта
docker-compose up -d

# Остановка Docker-проекта
docker-compose down
```

[В начало](#итоговый-проект)
