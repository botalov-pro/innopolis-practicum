<img src="../extra/img/innopolis-logo.svg" height="48px" href="#"/>

# ИТОГОВЫЙ ПРОЕКТ
# Игровая перспектива: Анализ жанров и платформ для разработки игр в 2025 году

Проект выполнен в рамках итоговой аттестации по курсу: "Программная инженерия. Разработка программного обеспечения (SQL для начинающих специалистов)" в Университете Иннополис.

Исполнитель: Боталов Константин Владимирович

Москва, 2024 г.

* [Ссылка](https://github.com/botalov-pro/innopolis-practicum/blob/main/exam/EXAM_FINAL.MD) на настоящую работу.
* [Ссылка](#) на презентацию проекта.
* [Ссылка](https://github.com/botalov-pro/innopolis-practicum/blob/main/exam/sql/exam_final.sql) на итоговый SQL-файл.
* [Ссылка](https://github.com/botalov-pro/innopolis-practicum/blob/main/exam/py/Botalov_KV_Global_games_sales_Analysis.ipynb) на итоговый файл Jupiter Notebook.

## Содержание

1. [Цель и задачи проекта](#цель-и-задачи-проекта)
2. [Основные инструменты проекта](#основные-инструменты-проекта)
3. [Описание исходных данных](#описание-исходных-данных)
4. [Загрузка данных](#загрузка-данных)
5. [Первичное исследование данных](#первичное-исследование-данных)

## Цель и задачи проекта

**Цель проекта** — определить c использованием SQL и методов программирования наиболее перспективные жанры и платформы для разработки компьютерных игр в 2025 году, а также рекомендовать подходящих издателей и выявить успешные игровые серии на основе анализа исторических данных о продажах.

**Задачи проекта:**

1. Загрузка и подготовка данных:
   - Загрузить данные о продажах компьютерных игр, включая информацию о жанрах, платформах, издателях и сериях игр.
   - Провести предварительную обработку данных: очистка, нормализация и устранение пропусков.
2. Анализ данных:
   - Провести описательный анализ данных для выявления общих тенденций в продажах по жанрам и платформам.
   - Использовать SQL-запросы для извлечения ключевых метрик, таких как средние продажи по жанрам и платформам, а также выявление наиболее успешных издателей.
3. Прогнозирование трендов:
   - Применить методы статистического анализа и машинного обучения для прогнозирования трендов в продажах игр на 2025 год.
   - Определить, какие жанры и платформы будут наиболее востребованы на основе исторических данных.
4. Выбор издателя и серии игр:
   - Проанализировать данные о наиболее успешных сериях игр и их издателях.
   - Рекомендовать наиболее подходящих издателей для разработки игр в выбранных жанрах и на выбранных платформах.
5. Интерпретация результатов и формулирование рекомендаций:
   - На основе проведенного анализа и прогнозов сформулировать рекомендации по разработке игр в 2025 году, включая выбор жанра, платформы и издателя.
   - Определить дальнейшие направления для исследования.

## Основные инструменты проекта

- **Рабочая операционная система:** Windows 11 Home 23H2
- **Среда контейнеризации приложений:** Docker Desktop 4.35.1
- **Система управления базами данных:** PostgreSQL 17.0 / pgAdmin 4 v8.12 (на базе ОС Debian) 
- **Языки программирования:** Python 3.12, SQL, PL/pgSQL
- **Интерактивное веб-приложение:** Jupyter Server 2.14.2 / Jupiter Notebook 7.2.2
- **Библиотеки:** Pandas 2.2.3, SQLAlchemy 2.0.36, psycopg 2.9.10

[Полный список зависимостей проекта](../requirements.txt)

## Описание исходных данных

Данные содержат информацию о продажах более 64 000 видеоигр во всем мире по состоянию на 2024 год с указанием наименований видеоигр, их издателях, количестве продаж, оценок критиков.

Информация автоматически собрана при помощи программного робота [vgchartz-crawler](https://github.com/baynebrannen/vgchartz-crawler) с сайта [Video Game Charts](https://www.vgchartz.com/). Владелец сайта - компания "VGChartz" (Video Game Charts) основана Бреттом Уолтоном и занимается аналитикой и исследованиями в мировой игровой индустрии с 2005 года.  

Файл с данными представлен файлом в формате CSV (Comma-Separated Values), который является распространенным и удобным способом представления табличных данных, что облегчает их обработку, анализ и
интеграцию с различными системами управления базами данных, программными средствами и аналитическими инструментами. Следовательно, мы можем этот набор данных загрузить и обработать
програмными средствами.

Последняя дата обновления данных: 29 января 2024 г. 18:58.

Данные распространяются под лицензией [ODC Attribution License (ODC-By)](https://opendatacommons.org/licenses/by/1-0/index.html)

Ссылка на исходный набор данных: https://www.kaggle.com/datasets/asaniczka/video-game-sales-2024

## Загрузка данных

1. Для первоначальной загрузки и анализа данных будем использовать средства Jupiter Notebook, Python, Pandas, так как мы не знаем какого рода данные содержатся в файле, их структуру, качество, количество и размер.  
2. Вручную загружаем исходный файл с расширением CSV в каталог ./src
3. В Jupiter Notebook импортируем необходимые для работы библиотеки:

```python
# Импорт необходимых библиотек
import os.path                      # os - для работы с файлами операционной системы
import pandas as pd                 # pandas - для работы с табличными данными
```

![](img/img_38.png)

4. Указываем путь к нашему файлу данных и проверяем, что файл доступен для загрузки:

```python
# Путь к исходному CSV-файлу
file_path = '../src/vgchartz-2024.csv'

# Проверка существования файла по заданному пути
os.path.exists(file_path)
```

![](img/img_39.png)

**Результат:** файл с данными существует в рабочем каталоге и доступен для загрузки. 

5. Загружаем данные файла в DataFrame Pandas:

```python
# Загрузка CSV файла в DataFrame Pandas
try:
    df = pd.read_csv(file_path)
    display('Файл загружен!')
except FileNotFoundError:
    display('Файл отсутствует!')
```

![](img/img_40.png)

6. Файл с данными загружен в дата-фрейм Pandas и готов для первичного исследования

## Первичное исследование данных

Первичное исследование данных в файле позволит ознакомиться с данными в нем, понять его структуру и подготовить данные для дальнейшей загрузки в базу данных.

Для первичного исследования данных продолжим использовать Python-библиотеку **Pandas** для анализа загруженного дата-фрейма. 

### Проверка типа загруженных данных

Проверим, что дата-фрейм - это наш тип загруженных данных 

```python
# Вывод типа переменной df - исследуемого набора данных
type(df)
```

![](img/img_41.png)

Данные загружены в виде необходимого нам дата-фрейма Pandas (*.DataFrame).
Приведение к другим типам данных в настоящее время не требуется.

### Проверка наличия данных

Для проверки наличия данных в файле вычислим 10 произвольных строк из набора данных:

```python
# Выводим десять случайных строк набора данных
df.sample(10)
```

![](img/img_42.png)

**Результат:** данные в наборе существуют и мы можем с ними работать.

### Определение размера и формы набора данных

Вычислим размер нашего набора данных и выведем названия столбцов:

```python
# Получение размера набора данных (количество строк и столбцов)
print(df.shape)

# Получение списка названий столбцов
print(df.columns)
```

![](img/img_43.png)

**Результат:** Наши данные содержат 64016 записей в 14 столбцах:

1. **img** - относительная ссылка (URI) на обложку игры с сайта [Video Game Charts](https://www.vgchartz.com/);
2. **title** - название игры;
3. **console** - компьютерная платформа (консоль) для которой была выпущена игра;
4. **genre** - жанр игры;
5. **publisher** - наименование издателя игры;
6. **developer** - наименование разработчика игры;
7. **critic_score** - оценка критиков (из 10);
8. **total_sales** - количество продаж во всем мире (в миллионах экземпляров);
9. **na_sales** - количество продаж в Северной Америке (в миллионах экземпляров);
10. **jp_sales** - количество продаж в Японии (в миллионах экземпляров);
11. **pal_sales** - количество продаж в странах PAL: Европа, Африка (в миллионах экземпляров);
12. **other_sales** - количество продаж в других регионах (в миллионах экземпляров);
13. **release_date** - дата выхода (релиза) игры;
14. **last_update** - дата последнего обновления данных.

### Проверка формата данных набора

Отобразим весь наш набор данных в сокращенном виде:

```python
# Отображение набора данных в сокращенном виде
display(df)
```

![](img/img_44.png)

![](img/img_45.png)

**Результат:** на первый взгляд какие-либо возможные проблемы с форматированием данных отсутствуют. Видим, что отсутствуют данные (NaN) в столбцах **critic_score**, **total_sales**, **na_sales**, **jp_sales**, **pal_sales**, **other_sales**, **release_date**, **last_update**.

### Определение количества уникальных значений при помощи Pandas

Для каждого столбца определим количество уникальных значений:

```python
# Подсчет количества уникальных значений для каждого столбца данных
display(df.nunique())
```

![](img/img_56.png)

**Результат:** из приведенных данных видим, что у нас 39798 уникальных названий игр, 81 платформа для компьютерных игр, 20 жанров, 3383 издателя и 8862 разработчика. Эта информация нам в дальнейшем поможет проверить правильность импорта данных и определить варианты оптимизации базы данных.

### Формат данных значений в наборе

Узнаем формат и количество значений в нашем наборе данных:

```python
# Вывод сводной информации о наборе данных
df.info()
```

![](img/img_46.png)

**Результат:** Данные занимают в памяти 6,8 Мб.

Значения в наборе представлены 8 категориальными и 6 числовыми признаками с
типами:
- **текстовые или смешанные данные** (object): img, title, console, genre, publisher, developer, release_date, last_update.  
- **число с плавающей запятой** (float64): critic_score, total_sales, na_sales, jp_sales, pal_sales, other_sales.

Видим, что в наборе данных присутствуют null-значения. Определим количество таких значений в столбцах:

```python
# Подсчет количества null-значений в наборе данных
df.isnull().sum()
```

![](img/img_47.png)

**Результат:** Как видим, в 9 столбцах из 14 (developer, critic_score, total_sales, na_sales, jp_sales, pal_sales, other_sales, release_date, release_date, last_update) присутствуют null-значения. Требуется обработка отсутствующих значений, так как в дальнейшем они могут вызвать ошибки при вычислениях.

Определим минимумы и максимумы для числовых значений. Это поможет нам в дальнейшем оптимальным образом построить структуру базы данных.

```python
# Определение минимумов и максимумов для числовых значений
df.describe()
```

![](img/img_48.png)

**Результат:** значения только в столбце critic_score ограничены значениями оценок от 1 до 10. Нижняя граница остальных числовых столбцов находится на отметке 0 (нет продаж или нет данным по ним). Максимальное значение фиксированной границы не имеет, так как данные актуализируются и растет количество проданных экземпляров игр. 

Данные загружены в дата-фрейм Pandas, проанализированы и готовы к импорту в систему управления базами данных.

## Перенос данных в базу данных

Для создания базы данных будем использовать систему управления реляционными базами данных PostgreSQL, развернутую в Docker-контейнере на базе операционной системы Debian. Для администрирования СУБД будем использовать pgAdmin.

### Создание чистой базы данных SALES

C использованием pgAdmin Query Tool создаем чистую базы данных **SALES**, предварительно удалив имеющуюся базу данных (если таковая имелась):

```postgresql
/* Удаление созданной базы данных SALES (если ранее такая база данных существовала) */
DROP DATABASE IF EXISTS sales;
```

![](img/img_49.png)

```postgresql
/* Создание чистой базы данных SALES */
CREATE DATABASE sales;
```

![](img/img_50.png)

Убеждаемся, что наша база данных SALES создалась:

```postgresql
/* Проверяем, что создалась база данных SALES */
SELECT datname FROM pg_database
WHERE datname='sales';
```

![](img/img_51.png)

**Результат:** чистая база данных SALES в PostgreSQL успешно создана.

### Задание 2: Импорт данных в базу данных

Для импорта данных дата-фрейма в базу данных SALES системы управления PostgreSQL будем использовать средства Pandas и SQLAlchemy.

В Jupiter Notebook импортируем необходимые нам библиотеки:

```python
# Импорт необходимых библиотек для переноса данных
from sqlalchemy import create_engine    # Набор инструментов для работы с SQL из Python
import psycopg2     # Коннектор к СУБД PostgreSQL из Python
```

![](img/img_52.png)

Создаем подключение к базе данных SALES и переносим данные из нашего дата-фрейма в таблицу SALES_IMPORT:

```python
# Импорт дата-фрейма в PostgreSQL средствами Pandas и SQLAlchemy

# Строка подключения к базе данных SALES
# Пример: 'postgresql://username:password@localhost:5432/your_database'
db_connection = create_engine('postgresql://postgres:changeme@localhost:5432/sales')

# Перенос данных из дата-фрейма в таблицу базы данных
df.to_sql(
    name='sales_import',    # Имя целевой таблицы
    con=db_connection,      # Подключение к базе данных
    if_exists='replace',    # если таблица уже существует, перезаписываем новыми знчениями
    index=False             # без индекса, он нам пока не требуется
)
```

![](img/img_53.png)

**Результат:** код успешно отработал и завершил перенос данных с дата-фрейма в базу данных. 

Так как метод **DataFrame.to_sql()** библиотеки **Pandas** не отражать точное количество записанных строк в базу данных, то проверяем успешность переноса данных:

```postgresql
/* Проверка количества импортированных данных в таблицу SALES_IMPORT */
SELECT COUNT(*) AS IMPORT_COUNT
    FROM sales_import;
```

![](img/img_54.png)

**Результат:** количество перенесенных строк соответствует количеству записей в дата-фрейме (64016).

Проверим качественный перенос данных и заполнение таблицы SALES_IMPORT. Выведем 10 произвольных строк из таблицы SALES_IMPORT:

```postgresql
/*
    Проверка качественного переноса импортированных данных в таблицу SALES_IMPORT.
    Вывод 10 случайных строк таблицы
*/
SELECT *
    FROM sales_import
    ORDER BY
        RANDOM()  -- Запускаем механизм случайности...
    LIMIT 10;  -- ...и извлекаем 10 случайных строк.
```

![](img/img_55.png)

**Результат:** данные успешно перенесены и теперь мы можем приступить к их анализу и оптимизации средствами SQL. 

## Анализ и подготовка данных средствами PostgreSQL

После того как мы загрузили данные в нашу базу данных необходимо их проанализировать средствами SQL и подготовить для дальнейшей оптимизации базы данных.

### Задание 3: Определение количества уникальных значений при помощи SQL

Определим с помощью SQL-запросов количество уникальных значений в нашей импортированной таблице SALES_IMPORT по каждому столбцу и сравним эти значения со [значениями, полученными при помощи библиотеки Pandas](#определение-количества-уникальных-значений-при-помощи-pandas):

```postgresql
/* Вывод таблицы с количеством уникальных значений по каждому столбцу */
DO $$
DECLARE
  cols TEXT;  -- Переменная для хранения агрегированного списка

BEGIN

    /*
        Очищаем (удаляем) временную таблицу counter
        перед ее заполнением
     */
    DROP TABLE IF EXISTS temp_counter;

    cols := string_agg(  -- объединяем строки в одну строку с разделителем (запятая)
                    'COUNT(DISTINCT ' || column_name::TEXT || ') '  || column_name::TEXT, ','
            )
    FROM (
        /*  Подзапрос для получения всех имен колонок из таблицы SALES_IMPORT */
        SELECT column_name
            FROM information_schema.columns
            WHERE
                table_name = 'sales_import'
            ) AS c;

    /*
       Создаем временную таблицу,
       где в качестве столбцов будут строки
       из переменной COLS (названия столбцов)
     */
    EXECUTE format(
            'CREATE TEMP TABLE temp_counter AS SELECT %s FROM sales_import;',
            cols
            );

END $$;

SELECT * FROM temp_counter;  -- Вывод данных из временной таблицы
```

![](img/img_57.png)

**Результат:** при помощи SQL-запроса мы получили данные о 39798 уникальном названии игры, 81 уникальной платформе, 20 уникальных жанрах, 3383 уникальном издателе, 8862 уникальном разработчике. Эти значения полностью совпадают со [значениями, полученными при помощи библиотеки Pandas](#определение-количества-уникальных-значений-при-помощи-pandas), что лишний раз подтверждает корректность импортированных данных. Кроме того, можно убедиться, что специальными библиотеками (типа Pandas) быстрее и проще анализировать данные нежели с использованием SQL-запросов.  

### Задание 4: Очистка от null-значений

Определим количество null-значений в нашей таблице SALES_IMPORT в каждом столбце:

```postgresql
/*
    Подсчет количества NULL-значений по каждому столбцу
*/
DO $$
DECLARE
  cols TEXT;  -- Переменная для хранения агрегированного списка

BEGIN

    -- Удаляем временную таблицу, если она существует
    DROP TABLE IF EXISTS temp_counter;

    cols := string_agg(  -- Объединяем строки в одну строку с разделителем (запятая)

                    /* Получаем разницу между общим количеством записей и ненулевыми значениями */
                    'COUNT(*) - COUNT(' || column_name::TEXT || ') AS ' || column_name::TEXT, ','
            )
    FROM (
        /* Подзапрос для получения всех имен колонок из таблицы sales_import */
        SELECT column_name
            FROM information_schema.columns
            WHERE
                table_name = 'sales_import'
            ) AS c;

    -- Создаем временную таблицу,
    -- где в качестве столбцов будут строки из переменной COLS (названия столбцов с подсчетом NULL)
    EXECUTE format(
            'CREATE TEMP TABLE temp_counter AS SELECT %s FROM sales_import;',
            cols
            );

END $$;

SELECT * FROM temp_counter;  -- Вывод данных из временной таблицы
```

![](img/img_58.png)

**Результат:** мы получили количество null-значений по каждому столбцу нашей таблицы.

На основе этих данных можно сделать следующие выводы:

- по полям **img**, **title**, **console**, **genre**, **publisher** - качество набора данных хорошее, т.к. отсутствуют null-значения;
- по полям ***_sales**, **critic_score**, **last_update** - качество набора данных слабое;
- в большинстве случаев дата выхода игры заполнена, что позволит нам построить временной ряд выпуска игр и выбрать правильный диапазон для дальнейшего исследования. 

Избавимся от null-значений путём установки новых значений:

- для данных о количестве продаж (*_sales) и critic_score заменим null-значения на 0;
- для release_date и last_update установим дату по умолчанию '1900-01-01';
- для неизвестных разработчиков установим значение '--UNKNOWN--'.

```postgresql
/*
    Очистка null-значений 
*/
UPDATE sales_import
SET 
    total_sales = COALESCE(total_sales, 0),
    na_sales = COALESCE(na_sales, 0),
    jp_sales = COALESCE(jp_sales, 0),
    pal_sales = COALESCE(pal_sales, 0),
    other_sales = COALESCE(other_sales, 0),
    critic_score = COALESCE(critic_score, 0),
    release_date = COALESCE(release_date, '1900-01-01'),
    last_update = COALESCE(last_update, '1900-01-01'),
    developer = COALESCE(developer, '--UNKNOWN--');
```

![](img/img_59.png)

**Результат:** Данные обновились новыми значениями.

Снова выполним запрос на подсчет количества NULL-значений по каждому столбцу.

![](img/img_60.png)

**Результат:** NULL-значения в таблице отсутствуют. Можем приступать к нормализации базы таблицы SALES_IMPORT и проектированию базы данных SALES.

## Проектирование и создание целевой базы данных

### Нормализация базы данных

#### Определение сущностей

На основе анализа таблицы SALES_IMPORT можно выделить следующие основные сущности:

```
- 'games' (Игры)
- 'consoles' (Консоли)
- 'genres' (Жанры)
- 'publishers' (Издатели)
- 'developers' (Разработчики)
```

#### Определение связей

Для обеспечения целостности данных и логического моделирования сущностей, определим связи между указанными сущностями:

* **Игры** доступны на нескольких **Консолях** (M:N)
* **Жанр** содержит множество **Игр** (1:N)
* **Издатель** выпускает **Игры** (1:N)
* **Разработчик** создает **Игры** (1:N)

#### Определение атрибутов

Определим основные атрибуты для каждой сущности, чтобы нормализовать базу данных:

| **Сущность 'games' (Игры)**                                                              |
|------------------------------------------------------------------------------------------|
| **id** (PK): уникальный идентификатор игры                                               |
| **title**: название игры                                                                 |
| **img**: обложка игры                                                                    |
| **console_id** (FK): идентификатор консоли игры                                          |
| **genre_id** (FK): идентификатор жанра игры                                              |
| **publisher_id** (FK): идентификатор издателя игры                                       |
| **developer_id** (FK): идентификатор разработчика игры                                   |
| **critic_score**: оценка критиков                                                        |
| **total_sales**: количество продаж во всем мире (в миллионах экземпляров)                |
| **na_sales**: количество продаж в Северной Америке (в миллионах экземпляров)             |
| **jp_sales**: количество продаж в Японии (в миллионах экземпляров)                       |
| **pal_sales**: количество продаж в странах PAL: Европа, Африка (в миллионах экземпляров) |
| **other_sales**: количество продаж в других регионах (в миллионах экземпляров)           |
| **last_update**: дата последнего обновления данных                                       |

| **Сущность 'consoles' (Консоли)**             |
|-----------------------------------------------|
| **id** (PK): уникальный идентификатор консоли |
| **name**: название консоли                    |

| **Сущность 'genres' (Жанры)**               |
|---------------------------------------------|
| **id** (PK): уникальный идентификатор жанра |
| **name**: название жанра                    |

| **Сущность 'publishers' (Издатели)**           |
|------------------------------------------------|
| **id** (PK): уникальный идентификатор издателя |
| **name**: название издателя                    |

| **Сущность 'developers' (Разработчики)**           |
|----------------------------------------------------|
| **id** (PK): уникальный идентификатор разработчика |
| **name**: название разработчика                    |

### Создание и наполнение целевой базы данных

#### Вычисление длины текстовых полей

Вычислим длины текстовых полей для использования в атрибутах сущностей. Длина текстового поля атрибута будет равна максимального значения длины этого поля в таблице SALES_IMPORT с коэффициентом 1.5 и округление до положительного числа.

```postgresql
/*
    Определение длины полей для текстовых значений:
    Максимальная длина поля * 1.5
*/
SELECT 
    ROUND(MAX(LENGTH(title)) * 1.5) AS max_title_length,
	ROUND(MAX(LENGTH(img)) * 1.5) AS max_img_length,
	ROUND(MAX(LENGTH(console)) * 1.5) AS max_console_length,
    ROUND(MAX(LENGTH(genre)) * 1.5) AS max_genre_length,
    ROUND(MAX(LENGTH(publisher)) * 1.5) AS max_publisher_length,
    ROUND(MAX(LENGTH(developer)) * 1.5) AS max_developer_length
FROM sales_import;
```

![](img/img_61.png)

**Результат:** определили длину текстовых полей атрибутов. Все поля уклыдываются в длину VARCHAR(255), поэтому будем ее использовать при определении длины текстовых полей. 

#### Создание и наполнение справочников

Создадим таблицы для справочников 'consoles' (Консоли), 'genres' (Жанры), 'publishers' (Издатели), 'developers' (Разработчики) предварительно удалив одноименные таблицы (если такие существуют):

```postgresql
/* Удаление таблиц справочников */
DROP TABLE IF EXISTS consoles;  -- Удаление таблицы сущности 'consoles' (Консоли)
DROP TABLE IF EXISTS genres;  -- Удаление таблицы сущности 'genres' (Жанры)
DROP TABLE IF EXISTS publishers;  -- Удаление таблицы сущности 'publishers' (Издатели)
DROP TABLE IF EXISTS developers;  -- Удаление таблицы сущности 'developers' (Разработчики)

/* Создание таблицы для сущности 'consoles' (Консоли) */
CREATE TABLE consoles (
    id SMALLSERIAL PRIMARY KEY,     -- Уникальный идентификатор консоли
    name VARCHAR(255) NOT NULL      -- Название консоли
);

/* Создание таблицы для сущности 'genres' (Жанры) */
CREATE TABLE genres (
    id SMALLSERIAL PRIMARY KEY,     -- Уникальный идентификатор жанра
    name VARCHAR(255) NOT NULL      -- Название жанра
);

/* Создание таблицы для сущности 'publishers' (Издатели) */
CREATE TABLE publishers (
    id SMALLSERIAL PRIMARY KEY,     -- Уникальный идентификатор издателя
    name VARCHAR(255) NOT NULL      -- Название издателя
);

/* Создание таблицы для сущности 'developers' (Разработчики) */
CREATE TABLE developers (
    id SMALLSERIAL PRIMARY KEY,     -- Уникальный идентификатор разработчика
    name VARCHAR(255) NOT NULL      -- Название разработчика
);
```

![](img/img_62.png)

**Результат:** таблицы справочников успешно созданы.

Заполняем данные в справочниках:

```postgresql
/*
    Заполнение таблицы-справочника 'consoles' (Консоли)
    и проверка заполнения таблицы
*/
INSERT INTO consoles(name)
    SELECT DISTINCT console
    FROM sales_import;

SELECT * FROM consoles;
```

![](img/img_63.png)

```postgresql
/*
    Заполнение таблицы-справочника 'genres' (Жанры)
    и проверка заполнения таблицы
*/
INSERT INTO genres(name)
    SELECT DISTINCT genre
    FROM sales_import;

SELECT * FROM genres;
```

![](img/img_64.png)

```postgresql
/*
    Заполнение таблицы-справочника 'publishers' (Издатели)
    и проверка заполнения таблицы
*/
INSERT INTO publishers(name)
    SELECT DISTINCT publisher
    FROM sales_import;

SELECT * FROM publishers;
```

![](img/img_65.png)

```postgresql
/*
    Заполнение таблицы-справочника 'developers' (Разработчики)
    и проверка заполнения таблицы
*/
INSERT INTO developers(name)
    SELECT DISTINCT developer
    FROM sales_import;

SELECT * FROM developers;
```

![](img/img_66.png)

## Прогнозирование трендов

## Выбор издателя и серии игр

## Основные выводы и рекомендации

## Направления дальнейших исследований